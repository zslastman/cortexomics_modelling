---
title: "linear deg/synth"
output: html_notebook
---
```{r}
# source(here::here('src/R/Rprofile.R'))
library(tidyverse)
```


```
# If we start parametrizing with dlP(t) + Kd, then we have gotten a 
logMinusExp<-function(ln_a,ln_b){
   log(exp(ln_a - ln_b) - 1) + ln_b
}

# since f` = f (ln f)` and f` = f`/f, and f` is an instantaneous fold changedFiles()
suppose the slope of ln2(f`) is one, then it it's doublng at a certain rate. Then 

so given that we have dlP(t)+Kd how to get P(t)?
so dlP(t)+Kd=l_synth_FC
dlP(t) = l_synth_FC - Kd
but since f`/f =  (log(f))`,and dlP(t) = log(P(t))`
P`(t)/P(t) = l_synth_FC - Kd
P`(t) =P(t)(l_synth_FC - Kd)

P`(t) = P(t) (l_synth_FC - Kd)

P(t) = exp(l_synth_FC - Kd )  + const

log(P(t)) = log ( exp (l_synth_FC - Kd) + const)



#Now not wholy clear how logs and spline approximations work.
#Can we validly approximate dlP(t) and P(t) on the same basis?
#I THINK so?

P` = R Ks - P Kd
=> P (log(P))` = RKs - P Kd
=> log(P)` = R Ks / P - Kd
log(P)`
so Kd is a log fold change

#for ref
log(P(t)) = log ( exp (l_synth_FC - Kd) + const)




log(R(t)) = log(P(t)) + log(dlP(t) + Kd) - log(Ks)
log(R(t)) = log(P(t)) + log(l_synth_FC(t)) - log(Ks)

#If we multiply my bs by the instantenous rates of change at the tps (the left vector)
#appending a start point, we get sensible vals on the right
#
m = matrix(c(10,20,20,-10,-10,-10),ncol=1)
#(mybs %*% m)%>%dput
Pt = structure(c(10, 30, 35, 25, 15), .Dim = c(5L, 1L))
fcs <- m[-1]/Pt
#Now we generate some param values that work
Kd = 0.70

lsynths = fcs + Kd

prot0=m[1]

#so given that I had Kd an dlsynth I couul dget the fold change at each point...
fcs <- lsynths - Kd

#now do a little math
#so the quantities we can calculuate

fcs = m[-1] Pt

fcs = m[-1]/(mybs %*% m )

fcs = m[-1] / (prot0 + (mybs[-1] %*% m[-1]))

(prot0 + (mybs[-1] %*% m[-1])) * fcs = m[-1]

prot0 * fcs + fcs * (mybs[-1] %*% m[-1]))  = m[-1]

prot0 * fcs + fcs * (mybs[-1] %*% m[-1])  = m[-1]

prot0 * fcs + fcs * (mybs[-1] %*% m[-1])  = m[-1]

prot0 * fcs  = m[-1] - fcs * (mybs[-1] %*% m[-1]) 

prot0 * fcs = (I - diag(fcs) mybss) %*% m[-1] 

prot0 * fcs = (I - diag(fcs) mybss) %*% m[-1] 

prot0 * fcs = (I - diag(fcs) mybss) %*% m[-1] 

(I - diag(fcs) mybss)^-1 %*%  prot0 * fcs = m[-1] 

fcs = lsynths - Kd

solve(diag(rep(1,5)) - diag(fcs[,1]) %*% mybs[,-1]) %*%  prot0 * fcs





#########################
#####WE DID IT TEAM
#########################

##!!!!

mym = solve(diag(rep(1,5)) - diag(fcs[,1]) %*% mybs[,-1]) %*%  (prot0 * fcs)

stopifnot(mybs %*% c(prot0,mym) == Pt
correctinv = solve(diag(rep(1,5)) - diag(newfcs[,1]) %*% mybs[,-1])
prot0 = m[1]

(prot0 * fcs)

#!!!!
#

#Now unclear what all the above means

# heres the basic relationship
P` = R Ks - P Kd
dbs %*% mp = dbs Ks - P Kd
dbs %*% mp = dbs %*% mr *  Ks - P Kd
#Now asusm dbs is I, and bs has no intercept column so we need prot 0   
mp = mr * Ks - (prot0 +  bs mp) Kd
mr * Ks = mp + Kd (prot0 +  bs mp)
mr * Ks = mp + Kd prot0 + bs mp
mr * Ks - Kd prot0 = mp + bs mp

mr * Ks - Kd prot0 = (I + bs ) mp

#sso to get mp
(I + bs )^-1 ( mr * Ks - Kd prot0) = mp
mr = (Kd prot0 + (I+bs) mp )/ Ks


Ks = 10
Kd = 0.5
prot0 = 1000
mr = c(20,20,20,20,20,20,20,200,20,20,20,20,20,20,20,20)
time = 1:length(mr)
library(splines)
library(splines2)
timeknots <- time[c(-1,-length(time))]
bs <- cbind(1,ibs(time, knots = timeknots,degree = 1, intercept = TRUE))
dbs = bs(time, knots = timeknots,degree = 1, intercept = TRUE)
I = diag(1,ncol=length(mr),nrow=length(mr))






```

so the above is an acceptable solution. The problem is, it doesn't have a clean determinant (from mr to mp)

What if I was to fix ribo0?




```{}
#THIS WORKS!
# OKay so... 
####Lets try to solve more efficiently
I = diag(rep(1,5))
A = I
BS = mybs[,1]
B = -D %*% mybs[,-1]
solve(A+B) %*% (prot0 * newfcs)
stopifnot(correctinv == solve(A+B))
inv=solve


#The woodbury matrix identity is https://en.wikipedia.org/wiki/Woodbury_matrix_identity
#it says that
inv(A + UCV) = inv(A) - inv(A) U inv(inv(C) + V inv(A) U) V inv(A)
#so what if I is A, I is also V, mybs is C , and D is U
then....
woodburymatrixsolve<-function(invA,U,invC,invV){
  inv(A) - inv(A) %*% U %*% inv(invC + V inv(A) U) V inv(A)
}
#suppose I do... D= U 

#NOPE

correctinv

inv(I - D %*%B) 

#from here?
#https://math.stackexchange.com/questions/17776/inverse-of-the-sum-of-matrices
I = diag(rep(1,5))
A = I
BS = mybs[,1]
B = -D %*% mybs[,-1]
solve(A+B) %*% (prot0 * newfcs)
correctinv = solve(A+B)
#uif B is rank 1
inv(A+B) = Inv(A) - 1/(1+trace(B%*%inv(A)))
#They then extend this to higher ranks.
#So what do I do?
#


#simpler matrix identities
#Now SOlve(AB) is solve(B)solve(A)
let diag(newfcs) = D, and mybs[,-1] = B
I want inv(I - D * B)
inv(I - D * B)
inv( D * (inv(D) *I - B ) )
inv( D * (inv(D) - B ) )
inv(inv(D) - B)*inv(D)

C_5^-1 = Cinv(4) - g(4)Cinv(4)B(4)C(inv4)


g(n) = 1/ (1+trace(Cinv(n)))
Cinv(1) = inv(A) 
Cinv(2) = Cinv(1) - g(1) Cinv(1) B(1) Cinv(1)
Cinv(2) = inv(A) - g(1) inv(A) B(1) inv(A)
#up to three
Cinv(3) = Cinv(2) - g(2) Cinv(2) B(1) Cinv(2)
Cinv(3) =inv(A) - g(1) inv(A) B(1) inv(A) - g(2) inv(A) - g(1) inv(A) B(1) inv(A)  B(2)  inv(A) - g(1) inv(A) B(1) inv(A)
#So this looks impractically complicated unless A or B is the identity matrix
Cinv(3) =inv(A) - g(1) inv(A) B(1) inv(A) - g(2) inv(A) - g(1) inv(A) B(1) inv(A)  B(2)  inv(A) - g(1) inv(A) B(1) inv(A)

Cinv(5) = Cinv(4) - g(4)Cinv(4)B(4)C(inv4)



#Could I now use woodbury on THAT???
#it says that
inv(A + UCV) = inv(A) - inv(A) U inv(inv(C) + V inv(A) U) V inv(A)
S

'"
##This is all defunct i think...
P(t) = mybs %*% m
and 
P'(t) = mydbs %*% m
#given my simple stepwise dbs we also have
P'(t) = m ; P(t) = mybs %*% m


#how do logs and splines even work?
if x ~= S %*% m #S = mydbs, Si = mybs
#dimensions in square brackets
#I think this doesn't generally even work...
#we can treat our t row vectors as happening in parallel
#But if we consider 1, then it's going to be S[1,1]m[1]+S[1,2]m[2]...etc
#That doesn't simplify, since log(a+b) generally doesn't
log(x[t]) ~= log(S[t,d] %*% m[d,1])
#But if S[t,d]=0 for all d!=t,
#then 
log(x[t]) = log(S[t,t])*m[t])
log(x[t]) = log(S[t,t])+log(m[t])
log(x[t]) = log(diag(S))+log(m[t])
log(x[t]) = 0+log(m[t])
#and note that this just reduces to log(x)=log(x) where S is identity and so x = m
#But can we use this to go from the log fold change params to the log amount?
let x = p'(t)
S %*% m  = p'(t)
log(S %*% m) = log(p'(t))
log(m) = log(p'(t))
#Is the log of the  differential equal to something?
log(m) = log(log'(P(t)) * P(t)) #Is this wrong maybe?
log(m) = log(log'(P(t))) + log(P(t))
log(m) - log(P(t)) = log(log'(P(t))) 
#??? How did I get here when the righ tside can be negative??????
exp(log(m) - log(P(t))) = log'(p(t))

exp(log(m) - log(Si%*%m) ) = log'(Si%*%m)

#not sure if this is going anywhere.
so agian x= p'(t)
#what we have from our parameters is log'(P(t))
#The problem is we need ot go from these to P(t) assuming INTERPOLATION in LINEAR SPADCE
#nope hang on, the right side of this can be negative, so how come
exp(log(m) - log(Si%*%m) ) = log'(Si%*%m)
exp(log(m) - log(Si%*%m) ) = 


##Should we abandon and just go linear?
Then we can posit linear fold change componenets
so that P'(t) = Ks R(t) + Kd P(t)
S m = P'(t)
Si m = P(t)
S m = Ks R(t) + Kd Si m
Ks R(t) = Sm - Kd Si m
R(t) = (Sm - Kd Si m) / Ks
log(R(t)) = log( S m - Kd Si m ) - log(Ks)
and
log(P(t)) = log( Si m)
#but now we still need to avoid taking the log of a negative number....
#Which we were partially doing before by using log splines....
#So S m must be greater than or equal to Kd Si m
meaning ... m > Kd Si m



#####BUT - all the above is very hard to vectorize in stan.
#What if we instead know prot0/m, the protein course, and Kd, the degredation rate?
#The problem here is that some values are impossible, log'(P(t)) must be above the fold change
m[-1] / (mybs %*% m ) - Kd > 0


###Okayyyy
or in other words
#So, my terminology was confusing me. m 
LFC = synth - Kd
Ks = 1
prot = mybs %*%c(prot0,LFC)
mRNA = prot + log(mydbs %*% (LFC+Kd) ) - log(Ks)
#
m

prot0=12
synth=c(2,2,1,4,5)*10
Kd = 10
prot = mybs%*%c(prot0,synth - Kd)
mRNA = prot + log(mydbs %*% synth)
add=`+`
ggpubr::ggarrange(plotlist=list(qplot(1:5,c(prot)),qplot(1:5,c(mRNA))))

```


```{stan modeltest,output.var =st_modeltest}


```

As per uri anlon or javonivic, if we have time dependent synthesis and decay, then Y(t) = exp(-Integrate(0,t,decay(t))) * (Y(0) + Integrate(0,t,Synthesis(t')exp(Integrate(0,t,decay(t)))))

(see page 37)


So. We want a form of D where - D = - Integrate(0,t,decay(t)), so the integrated decay rate from time 0 to time t. This appears in positive form to 'cancel out' some of the decay for the more recently produced molecules, in the right integral. If decay t is flat then it's just d_0 t. If it's a linear step it's ( (d_1 x^2) / 2) + d_0 x (put this in wolfram (integrate [ a + a_1 x  dx , 0 , t]) )

If we put this into wolfram:
 exp(  - d_0  T  )  * ( P_0 + Integrate [ R (s_0 + s_1 t ) * exp(  d_0 (t) )  dt , from 0 to T ] )


```{r}
# for(i in 2:length(ribo)){
# 
#       P[i] = stepsynthdeg(d_0=d_0,T=1,R = 2, s_0 = ribo[i-1],s_1 =  ribo[i] -  ribo[i-1],P_0 = P[i-1])
# 
# }

#Try putting this into wolfram alpha, and look at the expanded form.
# exp(  - d_0  T  )  * (P0 +   Integrate [  ( s_0 + (s_1 - s_0) t)  * exp( d_0 (t) )  dt , from 0 to T ] )
#NOt that this is with the two timepoints, not hte slope
#Now do that for T=1
## exp(  - d_0  T  )  * (P0 +   Integrate [  ( s_0 + (s_1 - s_0) t)  * exp( d_0 (t) )  dt , from 0 to T ] )


stepsynthdeg <- function(P_0,d_0,s_0,s_1,Ks=1,T=1){
      # exp = function(x){exp(log(2)*x)}
      s_0 = s_0 * Ks
      s_1 = s_1 * Ks
      P_0 * exp(-d_0) - exp(-d_0)*s_0*d_0^-1 - exp(-d_0)*s_0*d_0^-2  +  s_0*d_0^-2  +  s_1*d_0^-1  +  exp(-d_0)*s_1*(d_0^-2)  -  s_1*(d_0^-2)
}

#really don't undersatnd why this behaves so oddly

d_0 = 0.6;
Ks = 40;
ribo= c(10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 100, 100, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30);
P = rep(NA,length(ribo))
P[1] = 3* (ribo[1] * Ks)

for(i in 2:length(ribo)){
      P[i] = stepsynthdeg(d_0=d_0,Ks=Ks,T=1, s_0 = ribo[i-1],s_1 =  ribo[i],P_0 = P[i-1])
}

last(P) / last(ribo)


par(mfrow=(c(1,2)))
plot(ribo)
plot(P)
```


```{r}
#So that works, now can we do this in log space plz

#https://www.mathworks.com/matlabcentral/fileexchange/25273-methods-for-calculating-precise-logarithm-of-a-sum-and-subtraction
# 
# #to start with the above working expression.
# P_0 * exp(-d_0) - exp(-d_0)*s_0*d_0^-1 - exp(-d_0)*s_0*d_0^-2  +  s_0*d_0^-2  +  s_1*d_0^-1  +  exp(-d_0)*s_1*(d_0^-2)  -  s_1*(d_0^-2)
# 
# #Now let's put all the minuses on the right
# P_0 * exp(-d_0)  +  s_0*d_0^-2  +  s_1*d_0^-1  +  exp(-d_0)*s_1*(d_0^-2)  -  s_1*(d_0^-2) - exp(-d_0)*s_0*d_0^-1 - exp(-d_0)*s_0*d_0^-2
# 
# P_0 * exp(-d_0)  +  s_0*d_0^-2  +  s_1*d_0^-1  +  exp(-d_0)*s_1*(d_0^-2)  -  s_1*(d_0^-2) - exp(-d_0)*s_0*d_0^-1 - exp(-d_0)*s_0*d_0^-2

#Now supposing we want P_0, d_0, s_1 and s_0, to all be log 
# 
# #get this into logsum oand logsum minus
# logSumMinus(
#   logSum(P_0 * exp(-d_0)  ,  s_0*d_0^-2  ,  s_1*d_0^-1  ,  exp(-d_0)*s_1*(d_0^-2) ) ,
#   logSum(s_1*(d_0^-2) , exp(-d_0)*s_0*d_0^-1 , exp(-d_0)*s_0*d_0^-2)
# )
# 
# #and convert the multiplications to additions (and the exponentiations to multiplications)
# logSumMinus(
#   logSum(log(P_0) + log(exp(-d_0))  ,  log(s_0)+ log(d_0^-2)  ,  log(s_1)+log(d_0^-1)  ,log(exp(-d_0))+log(s_1)+log((d_0^-2)) ) ,
#   logSum(log(s_1)+log((d_0^-2)) , log(exp(-d_0))+log(s_0)+log(d_0^-1) , log(exp(-d_0))+log(s_0)+log(d_0^-2))
# )
# 
# library(matrixStats)
# logSumExp
# logSumMinus = function(a,b) log(exp(a - b) -1 )+b
#  
# logSumMinus(
#    logSumExp(c(log(P_0) + log(exp(-d_0))  ,  log(s_0)+ log(d_0^-2)  ,  log(s_1)+log(d_0^-1)  ,log(exp(-d_0))+log(s_1)+log((d_0^-2)) ) ),
#    logSumExp(c(log(s_1)+log((d_0^-2)) , log(exp(-d_0))+log(s_0)+log(d_0^-1) , log(exp(-d_0))+log(s_0)+log(d_0^-2)))
# )
# 
# #this works, now without multiplications and exponentiations
# lP_0 = log(P_0)
# ls_0 = log(s_0)
# ls_1 = log(s_1)
# dl = log(d_0)
# 
# logSumMinus(
#   logSumExp(c(lP_0 - exp(dl)  ,  ls_0 -2 *dl  ,  ls_1-dl  ,-exp(dl)+ls_1-2*dl )),
#   logSumExp(c(ls_1-2*dl , -exp(dl)+ls_0-dl , -exp(dl)+ls_0-2*dl))
# )

log_minus_exp <- function(a,b) {
    log(exp(a - b) -1 )+ b;
}
log_sum_exp <- function( a, b){
   log(exp(a - b) + 1) + b;
}

stepsynthdeg_log <- function(P_0,d_0,s_0,s_1,Ks=1,T=1){

    lP_0 = log(P_0)
    ls_0 = log(s_0) + log(Ks)
    ls_1 = log(s_1) + log(Ks)
    lKd = log(d_0)
    
    # 
    # dl = log(d_0) 
    # 
    # lP_1 = logSumMinus(
    #   logSumExp(c(lP_0 - exp(dl)  ,  ls_0 -2 *dl  ,  ls_1-dl  ,-exp(dl)+ls_1-2*dl )),
    #   logSumExp(c(ls_1-2*dl , -exp(dl)+ls_0-dl , -exp(dl)+ls_0-2*dl))
    # )
    # 
    # exp(lP_1)
    prot = array(c(lP_0,NA),c(1,2))
    lribo =  array(c(ls_0,ls_1),c(1,2))
    
    i = 2
    #Why does this code look like this? So I can copy paste it into stan of course!
      prot[,i] = prot[,i-1] - exp(lKd);
      prot[,i] = log_sum_exp(prot[,i], lribo[,i]-lKd);
      prot[,i] = log_sum_exp(prot[,i],-exp(lKd)+lribo[,i]-2*lKd );
    
      prot[,i] = log_sum_exp(prot[,i], lribo[,i-1]-lKd);
      prot[,i] = log_sum_exp(prot[,i],lribo[,i-1] -2 *lKd );
      prot[,i] = log_minus_exp(prot[,i],lribo[,i]-2*lKd );#9
      prot[,i] = log_minus_exp(prot[,i],-exp(lKd)+lribo[,i-1] - lKd );#2
      prot[,i] = log_minus_exp(prot[,i],lribo[,i-1] - lKd );#3
      prot[,i] = log_minus_exp(prot[,i],-exp(lKd)+lribo[,i-1] - 2*lKd );#4
  
        exp(prot[,2])
}

#So then, can we re-write the above working function in such a way that it 
Pe = rep(NA,length(ribo))
Pe[1] = P[1]
for(i in 2:length(ribo)){
      Pe[i] = stepsynthdeg_log(d_0=d_0,Ks=Ks,T=1, s_0 = ribo[i-1],s_1 =  ribo[i],P_0 = Pe[i-1])
}



plot(P,Pe)

```


So that code works - are we replicating it in stan? 


```{stan, verbose = TRUE,output.var = 'proDAsigmastan2'}

functions {
  vector log_minus_exp(vector a, vector b) {
   return log(exp(a - b) -1 )+ b;
  }
  vector log_sum_exp(vector a, vector b){
  return log(exp(a - b) + 1) + b;
  }

}


data {
  int G;// number of proteins
  int T;// info on the number of conditions
  matrix[G,T] lMSmu;
  matrix[G,T] lSeqmu;
  matrix[T,T] lMSsigma[G];
  matrix[T,T] lSeqsigma[G];
  real l_st_priorsd;
  real l_ribo_priorsd;
  real l_ribo_priornu;
  real l_pihalf_priormu;
  real l_pihalf_priorsd;
}

parameters {
  vector<lower=-10,upper=10>[G] l_st; // the ratio of steady state ratio to ribo
  matrix<lower=-10,upper=10>[G,T] lribo;  // log vector of ribo-seq levels
  vector<lower=-20,upper=20>[G] l_pihalf;  //log half life
  vector[G] prot0; // initial LOG amount of protein
}

transformed parameters{
    matrix [G,T] prot; // amounts of protein
    vector[G] Kd; // the degred
    vector[G] lKd; // the log degrad
    vector[G] lKs; // the (log) synthesis constant
    //get Kd
    lKd = log(log(2)) -  l_pihalf;
  
    //get Ks
    lKs = l_st -  lKd;
  
    prot[,1] = prot0;
    for(i in 2:T){
      // put thisinto wolfram  exp(  - d_0  T  )  * (P0 +   Integrate [  ( s_0 + (s_1 - s_0) t)  * exp( d_0 (t) )  dt , from 0 to T ] )
      //this is correct, but stans functions don't wory this way, we need to accumulate
     // prot[,i] = logSumMinus(
      //    log_sum_exp(prot[,i-1] - exp(lKd)  ,  lribo[,i-1] -2 *lKd  ,  lribo[,i]-lKd  ,-exp(lKd)+lribo[,i]-2*lKd ),
     //     log_sum_exp(lribo[,i]-2*lKd , -exp(lKd)+lribo[,i-1]-lKd , -exp(lKd)+lribo[,i-1]-2*lKd)
     // )
      prot[,i] = prot[,i-1] - exp(lKd);//1
      prot[,i] = log_sum_exp(prot[,i],lKs+ lribo[,i]-lKd);//5
      prot[,i] = log_sum_exp(prot[,i],lKs+-exp(lKd)+lribo[,i]-2*lKd );//6
    
      prot[,i] = log_sum_exp(prot[,i],lKs+lribo[,i-1]-lKd);//7
      prot[,i] = log_sum_exp(prot[,i],lKs+lribo[,i-1] -2 *lKd );//8
      prot[,i] = log_minus_exp(prot[,i],lKs+lribo[,i]-2*lKd );//9
      prot[,i] = log_minus_exp(prot[,i],lKs-exp(lKd)+lribo[,i-1] - lKd );//2
      prot[,i] = log_minus_exp(prot[,i],lKs+lribo[,i-1] - lKd );//3
      prot[,i] = log_minus_exp(prot[,i],lKs+-exp(lKd)+lribo[,i-1] - 2*lKd );//4

    }
}

model {
  // this needs to become steady state I think
  // for(c in 1:ncond){
    // l_st[,c] ~ normal(mu0, sqrt(sigma20));

  l_st ~ normal(0,l_st_priorsd);
  l_pihalf ~ normal(l_pihalf_priormu,l_pihalf_priorsd);
  
  //for(t in 1:T){
  //  lribo[,t] ~ student_t(l_ribo_priornu,0,l_ribo_priorsd);
  //}// put a prior on fold changes

  for(g in 1:G){
  
    lSeqmu[g] ~ multi_normal(lribo[g],lSeqsigma[g]);

    lMSmu[g]  ~ multi_normal(prot[g],lMSsigma[g]);
    
  }
  
}



generated quantities{
    matrix[G,T] lMSdev;
    lMSdev = prot - lMSmu;
}

```


```{r}
sampdata <- here('data/sampdata.rds')%>%read_rds
ribo <- c(10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 100, 100, 30, 
30, 30, 30, 30, 30, 30, 30, 30, 30)
nT = length(ribo)
stopifnot(length(Pe) == length(ribo))


sampdata$T=nT
sampdata$lMSmu = t(log(P)) #- median(log(P))
sampdata$lSeqmu = t(log(ribo)) #- median(log(ribo))
sampdata$lMSsigma = array(diag(rep(0.1,nT)),c(1,nT,nT))
sampdata$lSeqsigma = array(diag(rep(0.1,nT)),c(1,nT,nT))

time = 1:length(ribo)
timeknots <- time[c(-1,-length(time))]
sampdata$mybs =  cbind(1,ibs(time, knots = timeknots,degree = 1, intercept = TRUE))
sampdata$mydbs =bs(time, knots = timeknots,degree = 1, intercept = TRUE)

initvals=list()
initvals$prot0 <- array(sampdata$lMSmu[1],1)
Kd = d_0
lKd = log(Kd)
lpihalf = log(log(2)) - lKd
pihalf = log(2) / Kd
lpihalf = log(log(2)) - lKd
log(log(2)) - lpihalf
lKd
#log(log(2)) - lKd

initvals$l_pihalf <- array(lpihalf,1)
initvals$lribo = sampdata$lSeqmu
initvals$l_st = array(log(Ks) - lKd,1)

sampdata[names(sampdata)%>%str_subset('sd$')] %<>% map(multiply_by,10)
# 
# sampdata%>%map(dim)
# sampdata
# proDAsigmastan2

exp(opt$par$lKs)
exp(opt$par$l_st)


opt <- optimizing(proDAsigmastan2,data=sampdata,verbose=T,init=function(){initvals},as_vector=F,iter=1,save_iterations=TRUE)

#these aren't equal

initvals$l_pihalf;lpihalf
opt$par$l_pihalf;lpihalf
opt$theta_tilde[1,'l_pihalf[1]'];lpihalf

initvals$l_st;opt$par$l_st;opt$theta_tilde[1,'l_st[1]']


exp(opt$par$prot0)
exp(opt$par$prot[1,])



#Now let' 


log(log(2)) - opt$par$l_pihalf
opt$par$lKd

ggpubr::ggarrange(plotlist=list(
  qplot(y=Pe,x=seq_along(Pe),geom='point'),
  qplot(y=exp(opt$par$prot[1,]),x=seq_along(Pe),geom='point')
))

(Ks*ribo) / (last(Pe)*Kd)

#Ks is tooo high.

exp(opt$par$lKs)*exp(last(opt$par$lribo))
exp(opt$par$lKd)*exp(last(opt$par$prot))

#Thi sis a function of st and lKd
exp(opt$par$lKd)



```


THis is kiiiind of working.

So what if I optimize on the old params, since the above strategy of evaluating wth 1 iter isn't really working
```{r}

opt <- optimizing(proDAsigmastan2,data=sampdata,verbose=T,init=function(){initvals},as_vector=F,iter=1000,save_iterations=TRUE)

ggpubr::ggarrange(ncol=2,plotlist=list(
  qplot(y=Pe,x=seq_along(Pe),geom='point'),
  qplot(y=exp(opt$par$prot[1,]),x=seq_along(Pe),geom='point')
))

```



Victory!!!!








